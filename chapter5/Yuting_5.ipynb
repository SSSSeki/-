{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfbyJfq9XXvmXeHcW4LLUC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SSSSeki/-/blob/master/chapter5/Yuting_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1o5uWeh6Rvp",
        "outputId": "772fdd67-7b67-4507-fc57-9f786fc9d1e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In\n",
            "computer\n",
            "science\n",
            ",\n",
            "artificial\n",
            "intelligence\n",
            "(\n",
            "AI\n",
            ")\n",
            ",\n",
            "sometimes\n",
            "called\n",
            "machine\n",
            "intelligence\n",
            ",\n",
            "is\n",
            "intelligence\n",
            "demonstrated\n",
            "by\n",
            "machines\n",
            ",\n",
            "in\n",
            "contrast\n",
            "to\n",
            "the\n",
            "natural\n",
            "intelligence\n",
            "displayed\n",
            "by\n",
            "humans\n",
            "and\n",
            "animals\n",
            ".\n"
          ]
        }
      ],
      "source": [
        "#40\n",
        "import json\n",
        "class Word:\n",
        "  def __init__(self,token):\n",
        "    self.text = token['originalText']\n",
        "    self.lemma = token['lemma']\n",
        "    self.pos = token['pos']\n",
        "  #def __repr__(self):\n",
        "    #return self.text\n",
        "  def output(self):\n",
        "    return self.text\n",
        "\n",
        "filename = '/content/ai.en.txt.json'\n",
        "\n",
        "Text = []\n",
        "\n",
        "with open(filename, mode='r') as f:\n",
        "  json_data = json.load(f)\n",
        "  sentences = json_data['sentences']\n",
        "\n",
        "  for sen in sentences:\n",
        "    tokens = sen['tokens']\n",
        "    Sentence = []\n",
        "    for token in tokens:\n",
        "      Sentence.append(Word(token))\n",
        "    Text.append(Sentence)\n",
        "\n",
        "#test\n",
        "for word in Text[0]:\n",
        "  print(word.output())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#41\n",
        "Text = []\n",
        "\n",
        "class Word:\n",
        "  def __init__(self,token):\n",
        "    self.text = token['originalText']\n",
        "    self.lemma = token['lemma']\n",
        "    self.pos = token['pos']\n",
        "    self.head = None\n",
        "    self.dep = None\n",
        "    self.children = list()#[] doesnt work\n",
        "\n",
        "\n",
        "  def __repr__(self):\n",
        "    return self.text\n",
        "\n",
        "with open(filename, mode='r') as f:\n",
        "  json_data = json.load(f)\n",
        "  sentences = json_data['sentences']\n",
        "\n",
        "  for sen in sentences:\n",
        "    tokens = sen['tokens']\n",
        "    Sentence = []\n",
        "    for token in tokens:\n",
        "      Sentence.append(Word(token))\n",
        "    Text.append(Sentence)\n",
        "\n",
        "  i = 0\n",
        "  while i < len(sentences):\n",
        "    basicDependencies = sentences[i]['basicDependencies']\n",
        "\n",
        "    k = 0\n",
        "    while k < len(basicDependencies):\n",
        "      gov_index = basicDependencies[k]['governor']-1\n",
        "      dep_index = basicDependencies[k]['dependent']-1\n",
        "      if basicDependencies[k]['dep']!=\"ROOT\":\n",
        "        Text[i][dep_index].head = Text[i][gov_index]\n",
        "        Text[i][dep_index].dep = basicDependencies[k]['dep']\n",
        "        Text[i][gov_index].children.append(Text[i][dep_index])\n",
        "      k += 1\n",
        "    \n",
        "    i += 1 \n",
        "\n",
        "  while i < len(sentences):\n",
        "    basicDependencies = sentences[i]['basicDependencies']\n",
        "    k = 0\n",
        "\n",
        "    \n",
        "\n",
        "#test\n",
        "for word in Text[0]:\n",
        "   print(word,word.children,word.dep)"
      ],
      "metadata": {
        "id": "WFEtxuDsI5Y6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a53ee2eb-b7c6-4caa-ebbd-5687ef6eb50c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In [] case\n",
            "computer [] compound\n",
            "science [In, computer] nmod\n",
            ", [] punct\n",
            "artificial [] amod\n",
            "intelligence [artificial, AI, ,] nsubj\n",
            "( [] punct\n",
            "AI [(, )] appos\n",
            ") [] punct\n",
            ", [] punct\n",
            "sometimes [] advmod\n",
            "called [science, ,, intelligence, sometimes, intelligence, ,, is, .] None\n",
            "machine [] compound\n",
            "intelligence [machine] xcomp\n",
            ", [] punct\n",
            "is [intelligence] advcl\n",
            "intelligence [demonstrated, ,, contrast] nsubj\n",
            "demonstrated [machines] acl\n",
            "by [] case\n",
            "machines [by] nmod\n",
            ", [] punct\n",
            "in [] case\n",
            "contrast [in, intelligence] nmod\n",
            "to [] case\n",
            "the [] det\n",
            "natural [] amod\n",
            "intelligence [to, the, natural, displayed] nmod\n",
            "displayed [humans] acl\n",
            "by [] case\n",
            "humans [by, and, animals] nmod\n",
            "and [] cc\n",
            "animals [] conj\n",
            ". [] punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#42\n",
        "root_list = []\n",
        "\n",
        "for sen in Text:\n",
        "  for word in sen:\n",
        "    if word.head==None:\n",
        "      root_list.append((word))\n",
        "\n",
        "#test\n",
        "print(root_list[:10])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SskOgwZ5OsEK",
        "outputId": "2ee0c6ea-ecb2-4cc0-ec61-31a7f4c58dc9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[called, define, used, removed, says, excluded, classified, founded, divided, based]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#43\n",
        "verb_list = []\n",
        "for sen in Text:\n",
        "  for word in sen:\n",
        "    if word.pos.startswith(\"VB\"):\n",
        "        for child in word.children:\n",
        "          if child.pos.startswith(\"N\"):\n",
        "            verb_list.append((word,word.children))\n",
        "\n",
        "print(verb_list[:10])"
      ],
      "metadata": {
        "id": "EALShJ4dR5en",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e1aa137-6122-474a-bdf6-88f7d5f334ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(called, [science, ,, intelligence, sometimes, intelligence, ,, is, .]), (called, [science, ,, intelligence, sometimes, intelligence, ,, is, .]), (called, [science, ,, intelligence, sometimes, intelligence, ,, is, .]), (is, [intelligence]), (demonstrated, [machines]), (displayed, [humans]), (define, [textbooks, field, study, .]), (define, [textbooks, field, study, .]), (define, [textbooks, field, study, .]), (perceives, [that, environment, and, takes])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#44\n"
      ],
      "metadata": {
        "id": "a-PWSjMXsqZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#45\n",
        "tuple_list = []\n",
        "def dep_children(dep):\n",
        "  for child_dep in word.children:\n",
        "    if child_dep.dep == dep:\n",
        "      return child_dep\n",
        "\n",
        "for sen in Text:\n",
        "  for word in sen:\n",
        "    subj = None \n",
        "    obj = None\n",
        "    \n",
        "    if word.pos == \"VBD\":\n",
        "      subj = dep_children(\"nsubj\")\n",
        "      dobj = dep_children(\"dobj\")\n",
        "    if (subj is not None)and(dobj is not None):\n",
        "      tuple_list.append((subj,word,dobj))\n",
        "\n",
        "tuple_list[:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUXWcZa6tPLV",
        "outputId": "5057a9de-e4e6-459b-d7ec-5c72af42f0fd"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(characters, raised, many),\n",
              " (this, led, researchers),\n",
              " (They, produced, programs),\n",
              " (governments, cut, research),\n",
              " (project, inspired, U.S),\n",
              " (development, enabled, development),\n",
              " (match, defeated, champions),\n",
              " (computers, enabled, advances),\n",
              " (AlphaGo, won, 4),\n",
              " (AlphaGo, won, match),\n",
              " (who, held, ranking),\n",
              " (This, marked, completion),\n",
              " (they, had, AI),\n",
              " (China, accelerated, funding),\n",
              " (that, undiscovered, swans),\n",
              " (they, advocated, violence),\n",
              " (researchers, developed, algorithms),\n",
              " (that, imitated, reasoning),\n",
              " (they, experienced, explosion),\n",
              " (DeepMind, developed, intelligence),\n",
              " (number, explored, connection),\n",
              " (Some, built, machines),\n",
              " (that, used, networks),\n",
              " (one, developed, style),\n",
              " (Simon, studied, skills),\n",
              " (work, laid, foundations),\n",
              " (team, used, results),\n",
              " (people, used, algorithms),\n",
              " (Schank, described, approaches),\n",
              " (revolution, led, form),\n",
              " (Researchers, rejected, AI),\n",
              " (researchers, adopted, tools),\n",
              " (language, permitted, level),\n",
              " (each, cast, vote),\n",
              " (Rosenblatt, invented, perceptron),\n",
              " (Aizenberg, introduced, it),\n",
              " (publication, introduced, way),\n",
              " (LeCun, applied, backpropagation),\n",
              " (that, beat, champion),\n",
              " (NN, called, network),\n",
              " (recognition, experienced, jump),\n",
              " (Google, used, LSTM),\n",
              " (AlphaGo, brought, era),\n",
              " (formula, determined, dose),\n",
              " (machine, performed, diagnosis),\n",
              " (study, demonstrated, surgery),\n",
              " (team, supervised, robot),\n",
              " (it, performed, surgery),\n",
              " (AICPA, introduced, course),\n",
              " (AI, managed, systems),\n",
              " (which, took, place),\n",
              " (Association, dedicated, issue),\n",
              " (Electronica, opened, exhibitions),\n",
              " (Scientists, described, goals),\n",
              " (Musk, donated, $),\n",
              " (Wallach, introduced, concept),\n",
              " (Chalmers, identified, problems),\n",
              " (he, named, which),\n",
              " (research, produced, software),\n",
              " (survey, showed, disagreement),\n",
              " (Union, published, paper),\n",
              " (Asimov, introduced, Laws),\n",
              " (Sorayama, considered, robots)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#46"
      ],
      "metadata": {
        "id": "BZ92vCFx0b5e"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#47"
      ],
      "metadata": {
        "id": "gOiPqj328gma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#48 提取从根节点到名词的路径\n",
        "def word_to_gov(word):\n",
        "  if word.dep != None:\n",
        "    print(word,\"->\",end=\"\")    \n",
        "    word_to_gov(word.head)\n",
        "  else:\n",
        "    print(word)\n",
        "\n",
        "def paths_Extract(Text):\n",
        "  for sen in Text:\n",
        "    for word in sen:\n",
        "      if word.pos.startswith(\"N\"):\n",
        "        word_to_gov(word)\n",
        "#test\n",
        "for word in Text[0]:\n",
        "  if word.pos.startswith(\"N\"):\n",
        "    word_to_gov(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3eBwiV_8jaB",
        "outputId": "d8ee31da-7167-405f-846d-8843a55bddb7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "computer ->science ->called\n",
            "science ->called\n",
            "intelligence ->called\n",
            "AI ->intelligence ->called\n",
            "machine ->intelligence ->called\n",
            "intelligence ->called\n",
            "intelligence ->is ->called\n",
            "machines ->demonstrated ->intelligence ->is ->called\n",
            "contrast ->intelligence ->is ->called\n",
            "intelligence ->contrast ->intelligence ->is ->called\n",
            "humans ->displayed ->intelligence ->contrast ->intelligence ->is ->called\n",
            "animals ->humans ->displayed ->intelligence ->contrast ->intelligence ->is ->called\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#49"
      ],
      "metadata": {
        "id": "p5vwTQm48kgq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}